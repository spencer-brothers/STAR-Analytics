{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Home Credit Default Risk\n",
        "\n",
        "*Can you predict how capable each applicant is of repaying a loan?*\n",
        "\n",
        "Spencer Brothers, Radhika Bhakta, Amber Cash, Tami Salvador"
      ],
      "metadata": {
        "id": "SIx18NInsiEI"
      },
      "id": "SIx18NInsiEI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table of Contents\n",
        "\n",
        "1. [Introduction](#intro)\n",
        "2. [Models Considered](#models-considered)\n",
        "3. [Modeling Process](#model-process)\n",
        "4. [Model Performance](#model-performance)\n",
        "4. [Results](#results)"
      ],
      "metadata": {
        "id": "DBea059DQh9-"
      },
      "id": "DBea059DQh9-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction <a id=\"intro\"></a>\n",
        "The next step is to explore different modeling ideas for the project, with the aim of developing a model that beats a benchmark model (such as the majority class classifier) and produces results that -- hopefully! -- can be used to solve the business problem.\n",
        "\n",
        "### Business Problem\n",
        "\n",
        "Most lending services are based on credit, which excludes a large demographic of people (those with no credit history) from buying a home. Taking an uninformed lending approach is an unsustainable business practice that may leave underserved populations worse off, so using smart lending practices is essential to both Home Credit’s longevity and financial equity for unbanked populations.\n",
        "\n",
        "### Benefit of a Solution\n",
        "\n",
        "By better modeling clients’ behaviors, Home Credit can successfully predict clients’ repayment abilities. This supports Home Credit’s goals in two key areas:\n",
        "\n",
        "1.\tHome Credit will decrease costs of clients defaulting on loans or making late payments, supporting Home Credit's sustainability in an ever-changing economic and political ecosystem.\n",
        "\n",
        "2.\tClients capable of repayment will receive necessary resources that empower their financial success when other financial institutions fail to lend. Loans will be given with principal, maturity, and a repayment schedule that optimizes clients’ lending experience\n",
        "\n",
        "\n",
        "### Performance Benchmarks\n",
        "\n",
        "Because the data is highly imbalanced, with only 8.07% of observations belonging to the positive target class (`TARGET = 1`), a simple majority classifier would classify all applicants as not defaulting, having an accuracy of 91.97%, precision of 0, recall of 0, and thus an F-1 score of 0. We will try to exceed all of these in our model.\n",
        "\n",
        "We will also try to maximize the area under the Reciever Operating Characteristic Curve (ROC-AUC) for our model. Because a random classifier would have a ROC-AUC of 50%, we will try to exceed this value as well."
      ],
      "metadata": {
        "id": "h9J4CJkMQpNx"
      },
      "id": "h9J4CJkMQpNx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models Considered <a id=\"models-considered\"></a>\n",
        "\n",
        "### Naive Bayes Classifier\n",
        "\n",
        "#### Drop high-missing columns\n",
        "`\n",
        "df = df.dropna(thresh=len(df) * 0.6, axis=1)\n",
        "`\n",
        "\n",
        "#### Fill missing values\n",
        "`\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        df[col].fillna(df[col].mode()[0], inplace=True)  \n",
        "    else:\n",
        "        df[col].fillna(df[col].median(), inplace=True)  \n",
        "`\n",
        "\n",
        "#### Encode categorical features\n",
        "`\n",
        "df = pd.get_dummies(df, drop_first=True)  # One-hot encoding\n",
        "`\n",
        "\n",
        "#### Define features and target\n",
        "`\n",
        "X = df.drop(columns=['TARGET'])\n",
        "y = df['TARGET']\n",
        "`\n",
        "\n",
        "#### Normalize features using MinMaxScaler\n",
        "`\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "`\n",
        "\n",
        "#### Handle class imbalance using SMOTE\n",
        "`\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "`\n",
        "\n",
        "#### Split into training and testing sets\n",
        "`\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "`\n",
        "\n",
        "#### Train Naïve Bayes model\n",
        "`\n",
        "nb_classifier = GaussianNB()\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "`\n",
        "\n",
        "#### Predict and evaluate\n",
        "`\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "`\n",
        "\n",
        "This code performs a series of steps to preprocess a dataset and train a Naive Bayes classifier. It starts by loading the dataset and dropping columns with more than 40% missing values. It then fills missing values for categorical columns using the mode (most frequent value) and for numerical columns using the median. The categorical features are one-hot encoded, converting them into binary columns to make them suitable for machine learning models. The features are normalized using Min-Max scaling to bring all numerical variables into a consistent range between 0 and 1. To address class imbalance, the code applies SMOTE (Synthetic Minority Over-sampling Technique) to create synthetic samples for the minority class, ensuring the dataset has a more balanced distribution. The data is split into training and testing sets, with 80% used for training and 20% for testing. A Gaussian Naive Bayes classifier is trained on the resampled data, and predictions are made on the test set. The model's performance is evaluated through accuracy, a classification report (which includes precision, recall, F1-score, and support for each class), and a confusion matrix, providing a detailed assessment of the model's ability to correctly classify the target variable.\n",
        "\n",
        "The Naive Bayes model achieved an accuracy of 54%. The classification report shows high recall (94%) for defaulters (Class 1), meaning the model is effective at identifying those who default on loans. However, it struggles to correctly classify non-defaulters (Class 0), with only 14% recall, leading to a large number of false positives (48,653 cases). This shows great imbalance within this model. This is also reflected in the confusion matrix, where the model misclassifies most non-defaulters as defaulters while correctly predicting most actual defaulters. The likely causes include class imbalance, feature correlations, and the Naïve Bayes assumption of feature independence, which may not hold for financial data. To improve performance.\n",
        "\n",
        "\n",
        "\n",
        "### Tami\n",
        "\n",
        "TODO: Talk about the model(s) you used,\n",
        "\n",
        "TODO: Talk about performance of the model, discuss limitations of model\n",
        "\n",
        "TODO: if not blackbox: discuss insights into data\n",
        "\n",
        "### Logistic Regression\n",
        "\n",
        "In this analysis, I used logistic regression to predict loan default risk, leveraging various financial indicators such as income, credit amount, annuities, and previous loan history. The dataset was preprocessed by aggregating features from the bureau.csv and previous_application.csv files. The aggregated features were then merged with the main dataset to enrich the available predictors. Missing values were imputed using the median, and features were standardized for better model performance. The data was split into training and validation sets, ensuring stratification to handle class imbalance.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# Merge aggregated features with training data\n",
        "train_data = train_data.merge(bureau_agg, on='SK_ID_CURR', how='left')\n",
        "train_data = train_data.merge(previous_app_agg, on='SK_ID_CURR', how='left')\n",
        "\n",
        "# Select features and target\n",
        "features = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'DAYS_BIRTH',\n",
        "            'AMT_CREDIT_SUM_SUM', 'AMT_CREDIT_SUM_MEAN', 'AMT_CREDIT_SUM_DEBT_SUM', 'AMT_CREDIT_SUM_DEBT_MEAN',\n",
        "            'AMT_APPLICATION_MEAN', 'AMT_APPLICATION_MAX', 'AMT_CREDIT_MEAN', 'AMT_CREDIT_MAX']\n",
        "target = 'TARGET'\n",
        "\n",
        "X = train_data[features]\n",
        "y = train_data[target]\n",
        "\n",
        "# Handle missing values (simple imputation)\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "```\n",
        "The baseline model was a majority class classifier, which predicted the most frequent class (loan repaid) and achieved an accuracy of approximately 91% due to class imbalance. The logistic regression model was trained using 5-fold cross-validation, and the AUC score was used as a key performance metric. The initial logistic regression model achieved a ROC AUC score of approximately 0.67–0.70, indicating moderate predictive power.\n",
        "```\n",
        "# Baseline model: Majority class classifier (predicts the most frequent class)\n",
        "majority_class = y_train.mode()[0]\n",
        "y_majority_pred = np.full_like(y_val, majority_class)\n",
        "majority_accuracy = accuracy_score(y_val, y_majority_pred)\n",
        "print(f'Majority Class Accuracy: {majority_accuracy:.4f}')\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Fit logistic regression model with cross-validation\n",
        "model = LogisticRegression()\n",
        "cross_val_auc = cross_val_score(model, X_train_scaled, y_train, cv=kf, scoring='roc_auc')\n",
        "print(f'Cross-Validation AUC: {cross_val_auc.mean():.4f}')\n",
        "\n",
        "# Train logistic regression model on full training set\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_val_scaled)\n",
        "y_prob = model.predict_proba(X_val_scaled)[:, 1]\n",
        "\n",
        "# Evaluate model\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "roc_auc = roc_auc_score(y_val, y_prob)\n",
        "\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')\n",
        "print(f'Validation ROC AUC Score: {roc_auc:.4f}')\n",
        "```\n",
        "\n",
        "To improve model performance, an interaction term (INCOME_CREDIT_RATIO) was introduced, capturing the relationship between income and credit amount. This slightly improved the AUC score, but precision and recall did not increase significantly, suggesting that logistic regression might be too simplistic for this problem.\n",
        "\n",
        "```\n",
        "# Fit logistic regression models with interaction terms\n",
        "X_train['INCOME_CREDIT_RATIO'] = X_train['AMT_INCOME_TOTAL'] / X_train['AMT_CREDIT']\n",
        "X_val['INCOME_CREDIT_RATIO'] = X_val['AMT_INCOME_TOTAL'] / X_val['AMT_CREDIT']\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "model_interaction = LogisticRegression()\n",
        "model_interaction.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_interaction = model_interaction.predict(X_val_scaled)\n",
        "y_prob_interaction = model_interaction.predict_proba(X_val_scaled)[:, 1]\n",
        "\n",
        "# Evaluate interaction model\n",
        "accuracy_interaction = accuracy_score(y_val, y_pred_interaction)\n",
        "roc_auc_interaction = roc_auc_score(y_val, y_prob_interaction)\n",
        "\n",
        "print(f'Validation Accuracy with Interaction: {accuracy_interaction:.4f}')\n",
        "print(f'Validation ROC AUC Score with Interaction: {roc_auc_interaction:.4f}')\n",
        "```\n",
        "The data showed that features such as income, credit amount, and previous loan behavior had predictive value, but class imbalance remained a challenge so we moved onto other approaches.\n",
        "\n",
        "### Final Model Selection\n",
        "\n",
        "We used a XGBoost as our final model because it outperformed all of our benchmarks in 5-fold cross validation.\n"
      ],
      "metadata": {
        "id": "cmvUijvufvgG"
      },
      "id": "cmvUijvufvgG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup\n",
        "\n",
        "Import libraries and read in data"
      ],
      "metadata": {
        "id": "E9iMrtd9Qwgd"
      },
      "id": "E9iMrtd9Qwgd"
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "M6OmJTSaU28g"
      },
      "id": "M6OmJTSaU28g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, GridSearchCV, cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, make_scorer, precision_recall_curve\n"
      ],
      "metadata": {
        "id": "Tl8MbEpi1-_2"
      },
      "id": "Tl8MbEpi1-_2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mount to drive to access data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pqwmz8KAODe7",
        "outputId": "710ea54e-e053-44b6-86ad-107b527aa954"
      },
      "id": "Pqwmz8KAODe7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read raw data into pandas dataframes\n",
        "data_folder = '/content/drive/MyDrive/MSBA_Practice_Project/data'\n",
        "\n",
        "app_train = pd.read_csv(f'{data_folder}/application_train.csv')\n",
        "app_test = pd.read_csv(f'{data_folder}/application_test.csv')"
      ],
      "metadata": {
        "id": "i0uBao6zYebp"
      },
      "id": "i0uBao6zYebp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Engineering\n",
        "\n",
        "Along with `application_{train|test}.csv`, Home Credit also includes transactional datasets with information about each applicant. For this project, we will use `previous_application.csv` to hopefully improve our model performance. Because there are potentially multiple records for each applicant in `previous_application.csv`, we will make the following aggregations before joining the transactional data with `application_[train|test}.csv`:\n",
        "\n",
        "1. Proportion of Past Loans Refused (PROP_NAME_PREV_REFUSED)\n",
        "    - A high proportion of past loan refusals may indicate financial instability or a history of risky borrowing behavior, suggesting a higher likelihood of default.\n",
        "3. Average Time Since Loan Decision (AVG_DAYS_DECISION)\n",
        "\t- The recency of past credit decisions can provide insight into financial behavior. Frequent recent loan applications may indicate financial distress or an increased reliance on borrowing.\n",
        "4. Average Previous Credit Amount (AVG_PREV_CREDIT)\n",
        "\t- The typical size of previous loans can serve as an indicator of financial habits. Larger past loans may suggest significant debt obligations, which could impact the ability to repay future loans.\n",
        "5. Average Down Payment (AVG_DOWN_PAYMENT)\n",
        "\t- Consistently low down payments may suggest over-leveraging, increasing the risk of default by indicating a lack of financial reserves.\n",
        "6. Average Repayment Discrepancy (AVG_PREV_REPAYMENT_DISC)\n",
        "\t- The difference between the expected and actual last due date for previous loans can highlight repayment behavior. Large discrepancies may indicate late payments or loan extensions, both of which are potential risk factors.\n",
        "7. Average Rate of Down Payment (AVG_RATE_DOWN_PAYMENT)\n",
        "\t- A lower down payment rate may suggest that borrowers are stretching their finances to secure a loan, which could indicate higher financial risk.\n",
        "8. Count of Previous Loans (CNT_PREV_LOANS)\n",
        "\t- The total number of previous loans provides insight into borrowing patterns. A high number of past loans could indicate experience in managing debt but may also suggest a dependency on credit, which could be a risk factor."
      ],
      "metadata": {
        "id": "L_uJgcwv5zLE"
      },
      "id": "L_uJgcwv5zLE"
    },
    {
      "cell_type": "code",
      "source": [
        "# read transactional data into dataframe\n",
        "prev_app = pd.read_csv(f'{data_folder}/previous_application.csv')\n",
        "\n",
        "# Create a new column for the difference between DAYS_LAST_DUE and DAYS_LAST_DUE_1ST_VERSION\n",
        "prev_app[\"PREV_REPAYMENT_DISC\"] = prev_app[\"DAYS_LAST_DUE\"] - prev_app[\"DAYS_LAST_DUE_1ST_VERSION\"]\n",
        "\n",
        "# Aggregate previous applications\n",
        "prev_agg = prev_app.groupby(\"SK_ID_CURR\").agg(\n",
        "    # Proportion of past loans refused\n",
        "    PROP_NAME_PREV_REFUSED=(\"NAME_CONTRACT_STATUS\", lambda x: (x == \"Refused\").mean()),\n",
        "\n",
        "    # Average time since loan decision (recent approvals may indicate cash flow issues)\n",
        "    AVG_DAYS_DECISION=(\"DAYS_DECISION\", \"mean\"),\n",
        "\n",
        "    # Average previous credit amount (larger past loans might indicate risky borrowing behavior)\n",
        "    AVG_PREV_CREDIT=(\"AMT_CREDIT\", \"mean\"),\n",
        "\n",
        "    # Average down payment (low down payments suggest high leverage, possible risk)\n",
        "    AVG_DOWN_PAYMENT=(\"AMT_DOWN_PAYMENT\", \"mean\"),\n",
        "\n",
        "    # Average difference between actual and expected last due date (delayed repayment = risk)\n",
        "    AVG_PREV_REPAYMENT_DISC=(\"PREV_REPAYMENT_DISC\", \"mean\"),\n",
        "\n",
        "    # Average rate of down payment (low rates could indicate over-leveraging)\n",
        "    AVG_RATE_DOWN_PAYMENT=(\"RATE_DOWN_PAYMENT\", \"mean\"),\n",
        "\n",
        "    # Count of previous loans (a high number of past loans might indicate dependency on credit)\n",
        "    CNT_PREV_LOANS=(\"SK_ID_PREV\", \"count\")\n",
        ").reset_index()\n",
        "\n",
        "# Merge aggregated previous applications with application_train\n",
        "train_merged = app_train.merge(prev_agg, on=\"SK_ID_CURR\", how=\"left\")"
      ],
      "metadata": {
        "id": "NZ9JXUqY7gFI"
      },
      "id": "NZ9JXUqY7gFI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling Missing Data\n",
        "\n",
        "Many columns in the main dataset are mostly comprised of missing data, and most rows are missing data. By using binning and simple median imputation, we can fill all the missing data. While we may lose some detail in our data with binning, it offers a more accurate view of many highly predictive columns that may have structural missingness or where missing data represents a difference in populations, like in EXT_SOURCE{1|2|3}.\n",
        "\n",
        "#### Missing Categorical Data\n",
        "\n",
        "We used an LLM (Chat GPT 4o) to analyze the data dictionary, `HomeCredit_columns_description.csv`, and return a list of categorical features. We use this list to handle missing values in categorical columns, as well as encoding them as integers for model building and evaluation.\n",
        "\n",
        "While many categoriacal variables are nominal, we will use label encoding (assume all categorical variables are ordinal) to prevent excess dimensionality on an already large dataset."
      ],
      "metadata": {
        "id": "W36_VKiheIor"
      },
      "id": "W36_VKiheIor"
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_columns = [\n",
        "    'TARGET', 'NAME_CONTRACT_TYPE', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE',\n",
        "    'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL', 'OCCUPATION_TYPE', 'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY', 'ORGANIZATION_TYPE',\n",
        "    'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE',\n",
        "    'ENTRANCES_MODE', 'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'FONDKAPREMONT_MODE',\n",
        "    'HOUSETYPE_MODE', 'TOTALAREA_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE', 'OWN_CAR_AGE', 'APARTMENTS_AVG', 'BASEMENTAREA_AVG','YEARS_BUILD_AVG','COMMONAREA_AVG','ELEVATORS_AVG',\n",
        "    'ENTRANCES_AVG','FLOORSMIN_AVG','LANDAREA_AVG','LIVINGAPARTMENTS_AVG', 'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG', 'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI', 'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI',\n",
        "    'ELEVATORS_MEDI', 'ENTRANCES_MEDI', 'FLOORSMIN_MEDI',  'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', 'FLAG_DOCUMENT_2',\n",
        "    'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12',\n",
        "    'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21', 'REG_REGION_NOT_LIVE_REGION',\n",
        "    'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY', 'WEEKDAY_APPR_PROCESS_START', 'CODE_GENDER'\n",
        "]\n",
        "\n",
        "numeric_columns = [col for col in train_merged.columns.values if col not in categorical_columns]\n",
        "numeric_columns.remove('SK_ID_CURR')\n",
        "print(len(numeric_columns) + len(categorical_columns)) # sanity check: should be 128 = app_cols + agg_cols - 1 (ID_col)\n",
        "\n",
        "for col in tqdm(categorical_columns):\n",
        "  train_merged[col] = train_merged[col].astype(str).fillna('missing')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8jbhCHbfzXT",
        "outputId": "63739d15-f6cb-4538-826c-1fe9745aba74"
      },
      "id": "n8jbhCHbfzXT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 94/94 [00:12<00:00,  7.77it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Numeric Data\n",
        "\n",
        "Because this notebook is focusing on tree-based modeling algorithms, we will use binning to handle missing data."
      ],
      "metadata": {
        "id": "4SEUox8q3872"
      },
      "id": "4SEUox8q3872"
    },
    {
      "cell_type": "code",
      "source": [
        "# Bin numerical columns using quantiles\n",
        "max_bins = 50\n",
        "for col in tqdm(numeric_columns):\n",
        "  train_merged[col] = pd.qcut(train_merged[col], q=max_bins,labels=False, duplicates='drop').astype(str)\n"
      ],
      "metadata": {
        "id": "AYWyCw3YZbUR",
        "outputId": "09f3c23b-02bc-4312-e84b-72f00a6a4f33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "AYWyCw3YZbUR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 34/34 [00:04<00:00,  7.07it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fill missing values with 'missing'\n",
        "train_merged.replace('nan','missing',inplace=True)"
      ],
      "metadata": {
        "id": "jfSoBUsRo5sj"
      },
      "id": "jfSoBUsRo5sj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_merged"
      ],
      "metadata": {
        "id": "JBw31uM5zpH8",
        "outputId": "e6c4b746-bc80-40a8-ad0b-b5a7b990a931",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "id": "JBw31uM5zpH8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        SK_ID_CURR TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
              "0           100002      1         Cash loans           M            N   \n",
              "1           100003      0         Cash loans           F            N   \n",
              "2           100004      0    Revolving loans           M            Y   \n",
              "3           100006      0         Cash loans           F            N   \n",
              "4           100007      0         Cash loans           M            N   \n",
              "...            ...    ...                ...         ...          ...   \n",
              "307506      456251      0         Cash loans           M            N   \n",
              "307507      456252      0         Cash loans           F            N   \n",
              "307508      456253      0         Cash loans           F            N   \n",
              "307509      456254      1         Cash loans           F            N   \n",
              "307510      456255      0         Cash loans           F            N   \n",
              "\n",
              "       FLAG_OWN_REALTY CNT_CHILDREN AMT_INCOME_TOTAL AMT_CREDIT AMT_ANNUITY  \\\n",
              "0                    Y            0               16         18        24.0   \n",
              "1                    N            0               19         43        38.0   \n",
              "2                    Y            0                1          1         0.0   \n",
              "3                    Y            0               10         14        31.0   \n",
              "4                    Y            0                8         22        19.0   \n",
              "...                ...          ...              ...        ...         ...   \n",
              "307506               N            0               12          8        29.0   \n",
              "307507               Y            0                2         10         6.0   \n",
              "307508               Y            0               12         30        32.0   \n",
              "307509               Y            0               14         17        17.0   \n",
              "307510               N            0               12         29        46.0   \n",
              "\n",
              "        ... AMT_REQ_CREDIT_BUREAU_MON AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
              "0       ...                       0.0                       0.0   \n",
              "1       ...                       0.0                       0.0   \n",
              "2       ...                       0.0                       0.0   \n",
              "3       ...                   missing                   missing   \n",
              "4       ...                       0.0                       0.0   \n",
              "...     ...                       ...                       ...   \n",
              "307506  ...                   missing                   missing   \n",
              "307507  ...                   missing                   missing   \n",
              "307508  ...                       0.0                       0.0   \n",
              "307509  ...                       0.0                       0.0   \n",
              "307510  ...                       1.0                       0.0   \n",
              "\n",
              "       AMT_REQ_CREDIT_BUREAU_YEAR PROP_NAME_PREV_REFUSED AVG_DAYS_DECISION  \\\n",
              "0                             0.0                    0.0              31.0   \n",
              "1                             0.0                    0.0              11.0   \n",
              "2                             0.0                    0.0              24.0   \n",
              "3                         missing                    1.0              46.0   \n",
              "4                             0.0                    0.0              13.0   \n",
              "...                           ...                    ...               ...   \n",
              "307506                    missing                    0.0              46.0   \n",
              "307507                    missing                    0.0               0.0   \n",
              "307508                        0.0                    0.0               1.0   \n",
              "307509                        0.0                    0.0              44.0   \n",
              "307510                        0.0                    7.0              32.0   \n",
              "\n",
              "       AVG_PREV_CREDIT AVG_DOWN_PAYMENT AVG_PREV_REPAYMENT_DISC  \\\n",
              "0                 34.0              0.0                     9.0   \n",
              "1                 47.0             12.0                    15.0   \n",
              "2                  0.0             17.0                    16.0   \n",
              "3                 42.0             35.0                    24.0   \n",
              "4                 32.0             12.0                    23.0   \n",
              "...                ...              ...                     ...   \n",
              "307506             5.0              0.0                    16.0   \n",
              "307507             9.0             12.0                    19.0   \n",
              "307508             0.0             15.0                    19.0   \n",
              "307509            28.0              0.0                    36.0   \n",
              "307510            46.0             17.0                     6.0   \n",
              "\n",
              "       AVG_RATE_DOWN_PAYMENT CNT_PREV_LOANS  \n",
              "0                        0.0            0.0  \n",
              "1                        7.0            1.0  \n",
              "2                       33.0            0.0  \n",
              "3                       30.0            7.0  \n",
              "4                       30.0            4.0  \n",
              "...                      ...            ...  \n",
              "307506                   0.0            0.0  \n",
              "307507                  11.0            0.0  \n",
              "307508                  33.0            0.0  \n",
              "307509                   0.0            0.0  \n",
              "307510                  11.0            6.0  \n",
              "\n",
              "[307511 rows x 129 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1edbe0d0-64eb-4f0b-b629-f06a5f2a4cfd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SK_ID_CURR</th>\n",
              "      <th>TARGET</th>\n",
              "      <th>NAME_CONTRACT_TYPE</th>\n",
              "      <th>CODE_GENDER</th>\n",
              "      <th>FLAG_OWN_CAR</th>\n",
              "      <th>FLAG_OWN_REALTY</th>\n",
              "      <th>CNT_CHILDREN</th>\n",
              "      <th>AMT_INCOME_TOTAL</th>\n",
              "      <th>AMT_CREDIT</th>\n",
              "      <th>AMT_ANNUITY</th>\n",
              "      <th>...</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
              "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
              "      <th>PROP_NAME_PREV_REFUSED</th>\n",
              "      <th>AVG_DAYS_DECISION</th>\n",
              "      <th>AVG_PREV_CREDIT</th>\n",
              "      <th>AVG_DOWN_PAYMENT</th>\n",
              "      <th>AVG_PREV_REPAYMENT_DISC</th>\n",
              "      <th>AVG_RATE_DOWN_PAYMENT</th>\n",
              "      <th>CNT_PREV_LOANS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100002</td>\n",
              "      <td>1</td>\n",
              "      <td>Cash loans</td>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "      <td>24.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100003</td>\n",
              "      <td>0</td>\n",
              "      <td>Cash loans</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>43</td>\n",
              "      <td>38.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100004</td>\n",
              "      <td>0</td>\n",
              "      <td>Revolving loans</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100006</td>\n",
              "      <td>0</td>\n",
              "      <td>Cash loans</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>14</td>\n",
              "      <td>31.0</td>\n",
              "      <td>...</td>\n",
              "      <td>missing</td>\n",
              "      <td>missing</td>\n",
              "      <td>missing</td>\n",
              "      <td>1.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100007</td>\n",
              "      <td>0</td>\n",
              "      <td>Cash loans</td>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>22</td>\n",
              "      <td>19.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307506</th>\n",
              "      <td>456251</td>\n",
              "      <td>0</td>\n",
              "      <td>Cash loans</td>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>29.0</td>\n",
              "      <td>...</td>\n",
              "      <td>missing</td>\n",
              "      <td>missing</td>\n",
              "      <td>missing</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307507</th>\n",
              "      <td>456252</td>\n",
              "      <td>0</td>\n",
              "      <td>Cash loans</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>6.0</td>\n",
              "      <td>...</td>\n",
              "      <td>missing</td>\n",
              "      <td>missing</td>\n",
              "      <td>missing</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307508</th>\n",
              "      <td>456253</td>\n",
              "      <td>0</td>\n",
              "      <td>Cash loans</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>30</td>\n",
              "      <td>32.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307509</th>\n",
              "      <td>456254</td>\n",
              "      <td>1</td>\n",
              "      <td>Cash loans</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>17</td>\n",
              "      <td>17.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307510</th>\n",
              "      <td>456255</td>\n",
              "      <td>0</td>\n",
              "      <td>Cash loans</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>29</td>\n",
              "      <td>46.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>307511 rows × 129 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1edbe0d0-64eb-4f0b-b629-f06a5f2a4cfd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1edbe0d0-64eb-4f0b-b629-f06a5f2a4cfd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1edbe0d0-64eb-4f0b-b629-f06a5f2a4cfd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-31f7e967-32ab-4491-bfe5-a368ef21bc43\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-31f7e967-32ab-4491-bfe5-a368ef21bc43')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-31f7e967-32ab-4491-bfe5-a368ef21bc43 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_76c5f954-77cb-44ac-bb5a-33c9a544f04b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_merged')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_76c5f954-77cb-44ac-bb5a-33c9a544f04b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_merged');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_merged"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upsampling Data\n",
        "\n",
        "We tried oversampling the positive target class, but this reduced model performance in nearly every metric except the recall of our model."
      ],
      "metadata": {
        "id": "yRQrO9BJVZ-Y"
      },
      "id": "yRQrO9BJVZ-Y"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling Process <a id=\"model-process\"></a>\n",
        "\n",
        "We essentially de-linearized the data by binning because this notebook will focus on tree-based models. Specifically, we will train a XGBoost model, a gradient boosting algorithm. We tried implementing other gradient boosting algorithms, like CatBoost, but they took far to long to train. XGBoost is optimal for our use because it can be trained in parallel on the GPU, which significantly reduces execution times for hyperparameter tuning.\n",
        "\n",
        "Hyperparameters will be selected using a randomized search with 3-fold cross validation using the area under the ROC curve.\n",
        "\n",
        "The best model parameters will then be used to train a final XG Boost model, which we will evaluate in the next section.\n",
        "\n",
        "***NOTE*** : if using google colab, be careful about running this section, and make sure to use the A100 GPU Runtime."
      ],
      "metadata": {
        "id": "0ngf0mn9Q_Z-"
      },
      "id": "0ngf0mn9Q_Z-"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load & Preprocess Data\n",
        "X = train_merged.drop(columns=['TARGET', 'SK_ID_CURR'])  # Drop ID and target\n",
        "y = train_merged['TARGET'].astype(int)  # Extract target\n",
        "\n",
        "# Convert all categorical features to numerical values using Label Encoding\n",
        "label_encoders = {}\n",
        "for col in X.columns:\n",
        "    le = LabelEncoder()\n",
        "    X[col] = le.fit_transform(X[col])\n",
        "    label_encoders[col] = le  # Save encoders for later use if needed"
      ],
      "metadata": {
        "id": "UhtXEEve0aPj"
      },
      "id": "UhtXEEve0aPj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define XGBoost Model\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    tree_method='hist',\n",
        "    device='cuda', # Enable GPU acceleration\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Define Hyperparameter Grid for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': [500, 1000],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'max_depth': [4, 6, 8],\n",
        "    'reg_lambda': [1, 3, 5],  # L2 regularization\n",
        "    'subsample': [0.7, 1.0],  # Fraction of data to use per tree\n",
        "    'colsample_bytree': [0.7, 1.0]  # Fraction of features per tree\n",
        "}\n",
        "\n",
        "# Set Up RandomizedSearchCV\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_distributions=param_dist,\n",
        "    cv=cv,\n",
        "    scoring='roc_auc',\n",
        "    n_iter=30,  # Randomly test 30 parameter sets\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train with RandomizedSearchCV\n",
        "random_search.fit(X, y)\n",
        "\n",
        "# Output Best Hyperparameters\n",
        "print(\"Best parameters:\", random_search.best_params_)\n",
        "print(\"Best ROC AUC:\", random_search.best_score_)\n"
      ],
      "metadata": {
        "id": "i-JFdNtG1sve",
        "outputId": "844309b6-189e-4799-d694-292a43946ef5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "i-JFdNtG1sve",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'subsample': 1.0, 'reg_lambda': 5, 'n_estimators': 500, 'max_depth': 4, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
            "Best ROC AUC: 0.7616342715054478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code block took about 15 minutes to run, which isn't too bad considering we trained 150 ensemble models."
      ],
      "metadata": {
        "id": "pgvtASX_PIK8"
      },
      "id": "pgvtASX_PIK8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Performance <a id=\"model-performance\"></a>"
      ],
      "metadata": {
        "id": "8H0iYupRRR6V"
      },
      "id": "8H0iYupRRR6V"
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X, y, threshold=0.5, cv_splits=5):\n",
        "    # Perform Stratified K-Fold Cross-Validation\n",
        "    cv = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    # Get predicted probabilities for TARGET=1\n",
        "    y_pred_proba = cross_val_predict(model, X, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "\n",
        "    # Apply custom threshold\n",
        "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "    # Compute evaluation metrics\n",
        "    avg_scores = {\n",
        "        'Accuracy': accuracy_score(y, y_pred),\n",
        "        'Precision': precision_score(y, y_pred, pos_label=1, zero_division=0),\n",
        "        'Recall': recall_score(y, y_pred, pos_label=1),\n",
        "        'F1': f1_score(y, y_pred, pos_label=1),\n",
        "        'ROC AUC': roc_auc_score(y, y_pred_proba)  # ROC AUC remains unchanged\n",
        "    }\n",
        "\n",
        "    # Print evaluation results\n",
        "    print(\"\\nModel Evaluation with 5-Fold Cross-Validation (Threshold = {:.2f}):\".format(threshold))\n",
        "    for metric, score in avg_scores.items():\n",
        "        print(f\"Mean {metric}: {score:.4f}\")\n",
        "\n",
        "    return avg_scores"
      ],
      "metadata": {
        "id": "Tt0SPy3v0X45"
      },
      "id": "Tt0SPy3v0X45",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the best trained model\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "avg_scores_def_threshold = evaluate_model(best_model, X, y, threshold=0.5, cv_splits=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLBXqB_GKJRG",
        "outputId": "60dced4e-6761-48c5-d6c8-6086d9254a1f"
      },
      "id": "eLBXqB_GKJRG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Evaluation with 5-Fold Cross-Validation (Threshold = 0.50):\n",
            "Mean Accuracy: 0.9196\n",
            "Mean Precision: 0.5344\n",
            "Mean Recall: 0.0278\n",
            "Mean F1: 0.0529\n",
            "Mean ROC AUC: 0.7616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizing the Decision Threshold\n",
        "\n",
        "The evaluation above uses a decision threshold of 0.5, which has drawbacks. With a recall of about 2.8%, our model tends to approve bad loans, which increases risk of Home Credit incurring costs due to lendees defaulting. By lowering our decision threshold, our model will will have a higher recall but lower precision. Low precision in our model would represent rejecting good borrowers, decreasing Home Credit's revenue.\n",
        "\n",
        "We'd like to balance both precision and recall to ensure our model minimizes risk while still approving enough loans, so our decision threshold should maximise our model's F-1 score. This will come at the cost of lowering accuracy, but since the data is already so imbalanced with respect to the target class, accuracy isn't the best metric for evaluating model performance."
      ],
      "metadata": {
        "id": "1aeC38xfDTxZ"
      },
      "id": "1aeC38xfDTxZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Get model probabilities for TARGET=1\n",
        "y_pred_probs = best_model.predict_proba(X)[:, 1]\n",
        "\n",
        "# Compute precision-recall curve\n",
        "precisions, recalls, thresholds = precision_recall_curve(y, y_pred_probs)\n",
        "\n",
        "# Find the threshold that maximizes F1-score\n",
        "f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
        "best_F1_threshold = thresholds[f1_scores.argmax()]\n",
        "\n",
        "print(f\"Optimal Decision Threshold: {best_F1_threshold:.4f}\")"
      ],
      "metadata": {
        "id": "lyW3W_UamtLR",
        "outputId": "110049e8-a6d1-4320-df22-150592e0848c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lyW3W_UamtLR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Decision Threshold: 0.1707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_scores_best_threshold = evaluate_model(best_model, X, y, threshold=best_F1_threshold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mZfXifBIkCO",
        "outputId": "1f5337ff-4bef-4342-a177-a313866dfaec"
      },
      "id": "2mZfXifBIkCO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Evaluation with 5-Fold Cross-Validation (Threshold = 0.17):\n",
            "Mean Accuracy: 0.8666\n",
            "Mean Precision: 0.2649\n",
            "Mean Recall: 0.3677\n",
            "Mean F1: 0.3080\n",
            "Mean ROC AUC: 0.7616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results <a id=\"results\"></a>\n",
        "\n",
        "Overall, Our final model performed decently. With a mean ROC-AUC of 76.16% in cross validation, our model performs much better than a random classifier or simple majority classifier, but there's still room for improvement.\n",
        "\n",
        "If we were evaluating our model based solely on accuracy, we would use a decision threshold of 0.5 because it exceeded every benchmark set at the beginning of this document. However, as discusses previously, this may introduce unnecessary risks of lending to bad applicants.\n",
        "\n",
        "Using a lower decision threshold  better balances the risks of lending while still extending credit to trustworthy applicants, at the cost of model accuracy."
      ],
      "metadata": {
        "id": "k6NfMhTbRbBc"
      },
      "id": "k6NfMhTbRbBc"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "toc_visible": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}