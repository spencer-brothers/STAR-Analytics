{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling\n",
        "\n",
        "Spencer Brothers\n",
        "\n",
        "The next step is to explore different modeling ideas for the project, with the aim of developing a model that beats a benchmark model (such as the majority class classifier) and produces results that -- hopefully! -- can be used to solve the business problem.\n",
        "\n",
        "## Objectives\n",
        "\n",
        "- Practice feature engineering to improve model performance.\n",
        "\n",
        "- Practice cross-validation.\n",
        "\n",
        "- Learn about the properties of different modeling algorithms by experimenting with different methods and comparing different candidate models.\n",
        "\n",
        "- Learn from your group members.\n",
        "\n",
        "## Tasks\n",
        "\n",
        "- Set up a training set and a validation set using application_train.csv data set to do cross-validation.  Alternatively you could perform cross-validation using a different framework, such as k-fold cross validation as implemented in modeling packages such as caret or tidymodels or scikit-learn. The model performance that matters, of course, is the estimated performance on the test set as well as the Kaggle score.\n",
        "\n",
        "- Identify the performance benchmark established by the majority class classifier.\n",
        "\n",
        "- Fit several different logistic regression models using different predictors. Do interaction terms improve the model?  Compare model performance using not just accuracy but also AUC.\n",
        "Explore using algorithms like random forest and gradient boosting. Compare model performance.\n",
        "\n",
        "- Perform the data transformations required by a given algorithm.  For example, some algorithms require numeric data and perform better when it has been standardized or normalized.\n",
        "Experiment with upsampling and downsampling the data to adjust for the imbalanced target variable.  (See APM Ch. 16.)  Does this strategy this improve model performance?\n",
        "\n",
        "- Try combining model predictions--this is called an ensemble model--to improve performance.\n",
        "\n",
        "- Try additional feature engineering to boost model performance. Can you combine variables or bin numeric variables?  Explore the notebooks at Kaggle for data transformation ideas. In particular, use the other data sets at Kaggle--beyond the application data--to create additional features.\n",
        "\n",
        "- For machine learning models experiment with hyperparameter tuning  to try to boost performance.\n"
      ],
      "metadata": {
        "id": "SIx18NInsiEI"
      },
      "id": "SIx18NInsiEI"
    },
    {
      "cell_type": "code",
      "source": [
        "# Regression Section"
      ],
      "metadata": {
        "id": "_rie327GskHQ"
      },
      "id": "_rie327GskHQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "# Load data\n",
        "train_data = pd.read_csv('application_train.csv')\n",
        "bureau_data = pd.read_csv('bureau.csv')\n",
        "previous_app_data = pd.read_csv('previous_application.csv')\n",
        "\n",
        "# Aggregate bureau data\n",
        "bureau_agg = bureau_data.groupby('SK_ID_CURR').agg({\n",
        "    'AMT_CREDIT_SUM': ['sum', 'mean'],\n",
        "    'AMT_CREDIT_SUM_DEBT': ['sum', 'mean'],\n",
        "    'AMT_CREDIT_SUM_OVERDUE': ['sum', 'mean'],\n",
        "    'CNT_CREDIT_PROLONG': ['sum']\n",
        "})\n",
        "bureau_agg.columns = ['_'.join(col).upper() for col in bureau_agg.columns]\n",
        "bureau_agg.reset_index(inplace=True)\n",
        "\n",
        "# Aggregate previous application data\n",
        "previous_app_agg = previous_app_data.groupby('SK_ID_CURR').agg({\n",
        "    'AMT_APPLICATION': ['mean', 'max'],\n",
        "    'AMT_CREDIT': ['mean', 'max'],\n",
        "    'DAYS_DECISION': ['mean'],\n",
        "    'NAME_CONTRACT_STATUS': ['count']\n",
        "})\n",
        "previous_app_agg.columns = ['_'.join(col).upper() for col in previous_app_agg.columns]\n",
        "previous_app_agg.reset_index(inplace=True)\n",
        "\n",
        "# Merge aggregated features with training data\n",
        "train_data = train_data.merge(bureau_agg, on='SK_ID_CURR', how='left')\n",
        "train_data = train_data.merge(previous_app_agg, on='SK_ID_CURR', how='left')\n",
        "\n",
        "# Select features and target\n",
        "features = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'DAYS_BIRTH',\n",
        "            'AMT_CREDIT_SUM_SUM', 'AMT_CREDIT_SUM_MEAN', 'AMT_CREDIT_SUM_DEBT_SUM', 'AMT_CREDIT_SUM_DEBT_MEAN',\n",
        "            'AMT_APPLICATION_MEAN', 'AMT_APPLICATION_MAX', 'AMT_CREDIT_MEAN', 'AMT_CREDIT_MAX']\n",
        "target = 'TARGET'\n",
        "\n",
        "X = train_data[features]\n",
        "y = train_data[target]\n",
        "\n",
        "# Handle missing values (simple imputation)\n",
        "X.fillna(X.median(), inplace=True)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "# Baseline model: Majority class classifier (predicts the most frequent class)\n",
        "majority_class = y_train.mode()[0]\n",
        "y_majority_pred = np.full_like(y_val, majority_class)\n",
        "majority_accuracy = accuracy_score(y_val, y_majority_pred)\n",
        "print(f'Majority Class Accuracy: {majority_accuracy:.4f}')\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Fit logistic regression model with cross-validation\n",
        "model = LogisticRegression()\n",
        "cross_val_auc = cross_val_score(model, X_train_scaled, y_train, cv=kf, scoring='roc_auc')\n",
        "print(f'Cross-Validation AUC: {cross_val_auc.mean():.4f}')\n",
        "\n",
        "# Train logistic regression model on full training set\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_val_scaled)\n",
        "y_prob = model.predict_proba(X_val_scaled)[:, 1]\n",
        "\n",
        "# Evaluate model\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "roc_auc = roc_auc_score(y_val, y_prob)\n",
        "\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')\n",
        "print(f'Validation ROC AUC Score: {roc_auc:.4f}')\n",
        "\n",
        "# Fit logistic regression models with interaction terms\n",
        "X_train['INCOME_CREDIT_RATIO'] = X_train['AMT_INCOME_TOTAL'] / X_train['AMT_CREDIT']\n",
        "X_val['INCOME_CREDIT_RATIO'] = X_val['AMT_INCOME_TOTAL'] / X_val['AMT_CREDIT']\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "model_interaction = LogisticRegression()\n",
        "model_interaction.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_interaction = model_interaction.predict(X_val_scaled)\n",
        "y_prob_interaction = model_interaction.predict_proba(X_val_scaled)[:, 1]\n",
        "\n",
        "# Evaluate interaction model\n",
        "accuracy_interaction = accuracy_score(y_val, y_pred_interaction)\n",
        "roc_auc_interaction = roc_auc_score(y_val, y_prob_interaction)\n",
        "\n",
        "print(f'Validation Accuracy with Interaction: {accuracy_interaction:.4f}')\n",
        "print(f'Validation ROC AUC Score with Interaction: {roc_auc_interaction:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4voSK9OQbVE",
        "outputId": "94064ab7-ab03-4bff-c3d0-b5eb10b73d37"
      },
      "id": "l4voSK9OQbVE",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-d7345e4c8f1b>:47: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X.fillna(X.median(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Majority Class Accuracy: 0.9193\n",
            "Cross-Validation AUC: 0.6251\n",
            "Validation Accuracy: 0.9192\n",
            "Validation ROC AUC Score: 0.6218\n",
            "Validation Accuracy with Interaction: 0.9192\n",
            "Validation ROC AUC Score with Interaction: 0.6243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhRFvqWVcjfM",
        "outputId": "900e1547-233b-430e-8e46-ff0db8c97711"
      },
      "id": "WhRFvqWVcjfM",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RKRiVZhCQb2l"
      },
      "id": "RKRiVZhCQb2l",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}